{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ae3d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "import tkinter.font as tkFont\n",
    "from tkinter import filedialog\n",
    "import random\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d77e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(selection):\n",
    "    global model_number\n",
    "    data = pd.read_csv(\"/Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/Questions.csv\")\n",
    "    df2=data[data['Question']==clicked.get()]['ID']\n",
    "    model_number = df2.values[0]\n",
    "    \n",
    "def read_questionFile():\n",
    "    questions = []\n",
    "    question_data = pd.read_csv(\"/Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/Questions.csv\")\n",
    "    question = question_data[\"Question\"]\n",
    "    for q in question:\n",
    "        questions.append(q)\n",
    "    return questions\n",
    "\n",
    "def read_folder():\n",
    "    global folderpath , foldername\n",
    "    root.foldername = filedialog.askdirectory(initialdir=\"/Users/unaissiddiqui/Desktop/Fyp\", title=\"Select A Folder\")\n",
    "    head_tail = os.path.split(root.foldername)\n",
    "    ButtonFolder['text'] = head_tail[1]\n",
    "    folderpath = root.foldername\n",
    "    foldername = head_tail[1]\n",
    "\n",
    "def read_file():\n",
    "    global filepath, filename\n",
    "    root.filename = filedialog.askopenfilename(initialdir=\"/Users/unaissiddiqui/Desktop/Fyp\", title=\"Select A File\")\n",
    "    head_tail = os.path.split(root.filename)\n",
    "    ButtonFile['text'] = head_tail[1]\n",
    "    filepath = root.filename\n",
    "    filename = head_tail[1]\n",
    "    \n",
    "def ran_number():\n",
    "    random_number = random.randint(1000000,9999999)\n",
    "    data = pd.read_csv(\"/Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/Questions.csv\")\n",
    "    if random_number in data.values:\n",
    "        random_number = random.randint(1000000,9999999)\n",
    "    else:\n",
    "        return random_number\n",
    "\n",
    "def train():\n",
    "    Question_csv_list = []\n",
    "    random_number = ran_number()\n",
    "    Question_csv_list.append(random_number)\n",
    "    Question_csv_list.append(question.get())\n",
    "    f = open('/Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/Questions.csv', 'a')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(Question_csv_list)\n",
    "    f.close()\n",
    "    os.chdir(\"/Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader\")\n",
    "    os.system(\"rm -R data\")\n",
    "    os.system(\"mkdir data\")\n",
    "    os.system(\"rm -R Marks_csv\")\n",
    "    os.system(\"mkdir Marks_csv\")\n",
    "    os.chdir(\"/Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data\")\n",
    "    os.system(\"cp -R \"+ folderpath + \" \"+foldername)\n",
    "    os.system(\"mv \"+ foldername+\" Codes\")\n",
    "    os.chdir(\"/Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/Marks_csv\")\n",
    "    os.system(\"cp \"+ filepath + \" \"+filename)\n",
    "    os.system(\"mv \"+ filename+\" Data_Marks.csv\")\n",
    "    os.chdir(\"/Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader\")\n",
    "    os.system(\"./preprocess.sh 1 /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes Codes_embeddings\")\n",
    "    os.system(\"python train.py \"+str(random_number))\n",
    "    ButtonTrain['text'] = \"Trained\"\n",
    "\n",
    "def test():\n",
    "    os.chdir(\"/Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader\")\n",
    "    os.system(\"rm -R data\")\n",
    "    os.system(\"mkdir data\")\n",
    "    os.chdir(\"/Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data\")\n",
    "    os.system(\"cp -R \"+ folderpath + \" \"+foldername)\n",
    "    os.system(\"mv \"+ foldername+\" Codes\")\n",
    "    os.chdir(\"/Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader\")\n",
    "    os.system(\"./preprocess_test.sh 0 /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes Codes_embeddings\")\n",
    "    data = pd.read_csv(\"/Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/Values.csv\")\n",
    "    values_vocab_size = data[data['ID']==model_number]['word2idx'].values[0]\n",
    "    paths_vocab_size = data[data['ID']==model_number]['path2idx'].values[0]\n",
    "    labels_num = data[data['ID']==model_number]['target2idx'].values[0]\n",
    "    cmd = f\"python test.py {str(model_number)} {values_vocab_size} {paths_vocab_size} {labels_num}\"\n",
    "    os.system(cmd)\n",
    "    ButtonTest['text'] = \"Graded\"\n",
    "    \n",
    "def change_train():\n",
    "    ButtonTrain['text'] = \"Training..\"\n",
    "    ButtonTrain.after(400,train)\n",
    "\n",
    "def change_test():\n",
    "    ButtonTest['text'] = \"Grading..\"\n",
    "    ButtonTest.after(400,test)\n",
    "\n",
    "def back_train():\n",
    "    ButtonFolder.place_forget()\n",
    "    ButtonFile.place_forget()\n",
    "    ButtonTrain.place_forget()\n",
    "    ButtonBack.place_forget()\n",
    "    TitleLabel.place_forget()\n",
    "    questionLabel.place_forget()\n",
    "    FolderLabel.place_forget()\n",
    "    FileLabel.place_forget()\n",
    "    root_f()\n",
    "    \n",
    "def back_test():\n",
    "    ButtonFolder.place_forget()\n",
    "    QuestionLabel.place_forget()\n",
    "    FolderLabel.place_forget()\n",
    "    ButtonFolder.place_forget()\n",
    "    ButtonBack.place_forget()\n",
    "    ButtonTest.place_forget()\n",
    "    root_f()\n",
    "    \n",
    "def kill_train():\n",
    "    TitleLabel.place_forget()\n",
    "    Button_test_frame.place_forget()\n",
    "    Button_train_frame.place_forget()\n",
    "    TitleLabelS.place_forget()\n",
    "    train_f()\n",
    "    \n",
    "def kill_test():\n",
    "    TitleLabel.place_forget()\n",
    "    Button_test_frame.place_forget()\n",
    "    Button_train_frame.place_forget()\n",
    "    TitleLabelS.place_forget()\n",
    "    test_f()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a014a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_f():\n",
    "    global ButtonFolder, ButtonFile, ButtonTrain, ButtonBack, TitleLabel, questionLabel, FolderLabel, FileLabel, question\n",
    "    root.geometry(\"900x500\")\n",
    "\n",
    "    #Title Label\n",
    "    TitleLabel = Label(root,text=\"Train Model\")\n",
    "    ft = tkFont.Font(family='Copperplate',size=22)\n",
    "    TitleLabel[\"font\"] = ft\n",
    "    TitleLabel.place(x=350,y=15,width=200,height=35)\n",
    "\n",
    "    #Input Question\n",
    "    questionLabel = Label(root,text='Enter Question : ')\n",
    "    questionLabel.place(x=0,y=68,width=110,height=40)\n",
    "    question = Entry(root)\n",
    "    question.place(x=110,y=70,width=770,height=37)\n",
    "\n",
    "    #Select Folder\n",
    "    FolderLabel = Label(root,text='Select Folder :')\n",
    "    FolderLabel.place(x=0,y=130,width=95,height=40)\n",
    "    ft = tkFont.Font(family='Lucida Sans',size=13)\n",
    "    FolderLabel[\"font\"] = ft\n",
    "    ButtonFolder = Button(root,text=\"Upload Folder\",command=read_folder)\n",
    "    ButtonFolder.place(x=120,y=137,width=200,height=30)\n",
    "\n",
    "    #Select File\n",
    "    FileLabel = Label(root,text='Select Marks File :')\n",
    "    FileLabel.place(x=2,y=195,width=110,height=40)\n",
    "    ft = tkFont.Font(family='Lucida Sans',size=13)\n",
    "    FileLabel[\"font\"] = ft\n",
    "    ButtonFile = Button(root,text=\"Upload File\",command=read_file)\n",
    "    ButtonFile.place(x=120,y=200,width=200,height=30)\n",
    "\n",
    "    #Train Button\n",
    "    ButtonTrain = Button(root,text=\"Train\",command=change_train)\n",
    "    ButtonTrain.place(x=350,y=270,width=200,height=30)\n",
    "    \n",
    "    #Back Button\n",
    "    ButtonBack = Button(root, text=\"Back\", command=back_train)\n",
    "    ButtonBack.place(x=400,y=350,width=100,height=30)\n",
    "    \n",
    "\n",
    "def test_f():\n",
    "    global ButtonFolder, QuestionLabel, FolderLabel, ButtonFolder, ButtonBack, clicked, ButtonTest\n",
    "    root.geometry(\"900x700\")\n",
    "\n",
    "    #Title Label\n",
    "    TitleLabel = Label(root,text=\"Code Grader\")\n",
    "    ft = tkFont.Font(family='Copperplate',size=22)\n",
    "    TitleLabel[\"font\"] = ft\n",
    "    TitleLabel.place(x=350,y=15,width=200,height=35)\n",
    "\n",
    "    #Select Question\n",
    "    QuestionLabel = Label(root,text='Select Question :')\n",
    "    QuestionLabel.place(x=0,y=68,width=110,height=40)\n",
    "    ft = tkFont.Font(family='Lucida Sans',size=13)\n",
    "    QuestionLabel[\"font\"] = ft\n",
    "    questions = read_questionFile()\n",
    "    clicked = StringVar()\n",
    "    clicked.set(\"Questions\")\n",
    "    drop = OptionMenu(root,clicked,*questions,command=get_model)\n",
    "    drop.size\n",
    "    drop.place(x=110,y=70,width=770,height=40)\n",
    "\n",
    "    #Select Folder\n",
    "    FolderLabel = Label(root,text='Select Folder :')\n",
    "    FolderLabel.place(x=0,y=130,width=95,height=40)\n",
    "    ft = tkFont.Font(family='Lucida Sans',size=13)\n",
    "    FolderLabel[\"font\"] = ft\n",
    "    ButtonFolder = Button(root,text=\"Upload Folder\",command=read_folder)\n",
    "    ButtonFolder.place(x=110,y=137,width=200,height=30)\n",
    "    \n",
    "    #Train Button\n",
    "    ButtonTest = Button(root,text=\"Grade\",command=change_test)\n",
    "    ButtonTest.place(x=350,y=200,width=200,height=30)\n",
    "    \n",
    "    #Back Button\n",
    "    ButtonBack = Button(root, text=\"Back\", command=back_test)\n",
    "    ButtonBack.place(x=400,y=650,width=100,height=30)\n",
    "    \n",
    "\n",
    "  \n",
    "    \n",
    "def root_f():\n",
    "    global TitleLabel, Button_test_frame, Button_train_frame, TitleLabelS\n",
    "    root.title(\"Automated Code Grader\")\n",
    "    root.geometry(\"500x300\")\n",
    "\n",
    "    #Title Label\n",
    "    TitleLabel = Label(root,text=\"AUTOMATED CODE GRADER\")\n",
    "    ft = tkFont.Font(family='Copperplate',size=22)\n",
    "    TitleLabel[\"font\"] = ft\n",
    "    TitleLabel.place(x=10,y=15,width=500,height=65)\n",
    "\n",
    "    #Select Question\n",
    "    TitleLabelS = Label(root,text=\"Do you want to Grade the codes or train a new Model\")\n",
    "    ft = tkFont.Font(family='Copperplate',size=15)\n",
    "    TitleLabelS[\"font\"] = ft\n",
    "    TitleLabelS.place(x=5,y=70,width=500,height=65)\n",
    "\n",
    "    #Select Folder\n",
    "    Button_test_frame = Button(root,text=\"Grade Codes\",command=kill_test)\n",
    "    Button_test_frame.place(x=150,y=150,width=200,height=30)\n",
    "\n",
    "    #Train Button\n",
    "    Button_train_frame = Button(root,text=\"Train Model\",command=kill_train)\n",
    "    Button_train_frame.place(x=150,y=200,width=200,height=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8a2cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting paths from data set...\n",
      "Finished extracting paths from data set\n",
      "Calculating lines\n",
      "N: 835, train_n 709, test_n 63, val_n 63\n",
      "Extracting samples to raw files.\n",
      "Done extracting samples to raw files.\n",
      "Creating histograms from the training data\n",
      "Done creating histograms...sending to code2vec for preprocessing\n",
      "File: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.test.raw.txt\n",
      "Average total contexts: 420.12698412698415\n",
      "Average final (after sampling) contexts: 199.015873015873\n",
      "Total examples: 63\n",
      "Empty examples: 0\n",
      "Max number of contexts per word: 756\n",
      "File: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.val.raw.txt\n",
      "Average total contexts: 391.85483870967744\n",
      "Average final (after sampling) contexts: 199.70967741935485\n",
      "Total examples: 62\n",
      "Empty examples: 0\n",
      "Max number of contexts per word: 582\n",
      "File: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.train.raw.txt\n",
      "Average total contexts: 423.64022662889516\n",
      "Average final (after sampling) contexts: 199.46175637393767\n",
      "Total examples: 706\n",
      "Empty examples: 3\n",
      "Max number of contexts per word: 3794\n",
      "{'5.0': 28, '10.0': 283, '2.5': 70, '7.5': 328}\n",
      "Dictionaries saved to: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.dict.c2v\n",
      "Epoch 1: train loss - 1.76726, validation loss - 1.26143\n",
      "\t Validation: precision - 0.48387, recall - 0.48387, f1_score - 0.48387\n",
      "\t  accuracy - 0.49206\n",
      "Elapsed time: 2.123\n",
      "----------------------------------------------------------------------\n",
      "Epoch 2: train loss - 1.29425, validation loss - 1.17768\n",
      "\t Validation: precision - 0.51613, recall - 0.51613, f1_score - 0.51613\n",
      "\t  accuracy - 0.5082\n",
      "Elapsed time: 1.169\n",
      "----------------------------------------------------------------------\n",
      "Epoch 3: train loss - 1.181, validation loss - 1.17452\n",
      "\t Validation: precision - 0.48387, recall - 0.48387, f1_score - 0.48387\n",
      "\t  accuracy - 0.49206\n",
      "Elapsed time: 1.586\n",
      "----------------------------------------------------------------------\n",
      "Epoch 4: train loss - 1.10523, validation loss - 1.10867\n",
      "\t Validation: precision - 0.51613, recall - 0.51613, f1_score - 0.51613\n",
      "\t  accuracy - 0.5082\n",
      "Elapsed time: 4.709\n",
      "----------------------------------------------------------------------\n",
      "Epoch 5: train loss - 1.08108, validation loss - 1.09711\n",
      "\t Validation: precision - 0.53226, recall - 0.53226, f1_score - 0.53226\n",
      "\t  accuracy - 0.51667\n",
      "Elapsed time: 7.308\n",
      "----------------------------------------------------------------------\n",
      "Epoch 6: train loss - 1.09026, validation loss - 1.09743\n",
      "\t Validation: precision - 0.54839, recall - 0.54839, f1_score - 0.54839\n",
      "\t  accuracy - 0.52542\n",
      "Elapsed time: 8.282\n",
      "----------------------------------------------------------------------\n",
      "Epoch 7: train loss - 1.07637, validation loss - 1.10918\n",
      "\t Validation: precision - 0.45161, recall - 0.45161, f1_score - 0.45161\n",
      "\t  accuracy - 0.47692\n",
      "Elapsed time: 8.289\n",
      "----------------------------------------------------------------------\n",
      "Epoch 8: train loss - 1.07282, validation loss - 1.11051\n",
      "\t Validation: precision - 0.45161, recall - 0.45161, f1_score - 0.45161\n",
      "\t  accuracy - 0.47692\n",
      "Elapsed time: 8.480\n",
      "----------------------------------------------------------------------\n",
      "Epoch 9: train loss - 1.10473, validation loss - 1.10979\n",
      "\t Validation: precision - 0.51613, recall - 0.51613, f1_score - 0.51613\n",
      "\t  accuracy - 0.5082\n",
      "Elapsed time: 8.320\n",
      "----------------------------------------------------------------------\n",
      "Epoch 10: train loss - 1.06258, validation loss - 1.11891\n",
      "\t Validation: precision - 0.53226, recall - 0.53226, f1_score - 0.53226\n",
      "\t  accuracy - 0.51667\n",
      "Elapsed time: 8.676\n",
      "----------------------------------------------------------------------\n",
      "Epoch 11: train loss - 1.06705, validation loss - 1.12738\n",
      "\t Validation: precision - 0.53226, recall - 0.53226, f1_score - 0.53226\n",
      "\t  accuracy - 0.51667\n",
      "Elapsed time: 8.131\n",
      "----------------------------------------------------------------------\n",
      "Epoch 12: train loss - 1.04867, validation loss - 1.12927\n",
      "\t Validation: precision - 0.51613, recall - 0.51613, f1_score - 0.51613\n",
      "\t  accuracy - 0.5082\n",
      "Elapsed time: 7.520\n",
      "----------------------------------------------------------------------\n",
      "Epoch 13: train loss - 1.06174, validation loss - 1.12838\n",
      "\t Validation: precision - 0.43548, recall - 0.43548, f1_score - 0.43548\n",
      "\t  accuracy - 0.4697\n",
      "Elapsed time: 7.690\n",
      "----------------------------------------------------------------------\n",
      "Epoch 14: train loss - 1.05592, validation loss - 1.12735\n",
      "\t Validation: precision - 0.41935, recall - 0.41935, f1_score - 0.41935\n",
      "\t  accuracy - 0.46269\n",
      "Elapsed time: 7.522\n",
      "----------------------------------------------------------------------\n",
      "Epoch 15: train loss - 1.07639, validation loss - 1.12342\n",
      "\t Validation: precision - 0.51613, recall - 0.51613, f1_score - 0.51613\n",
      "\t  accuracy - 0.5082\n",
      "Elapsed time: 8.429\n",
      "----------------------------------------------------------------------\n",
      "Epoch 16: train loss - 1.06212, validation loss - 1.12303\n",
      "\t Validation: precision - 0.53226, recall - 0.53226, f1_score - 0.53226\n",
      "\t  accuracy - 0.51667\n",
      "Elapsed time: 8.043\n",
      "----------------------------------------------------------------------\n",
      "Epoch 17: train loss - 1.03543, validation loss - 1.12698\n",
      "\t Validation: precision - 0.51613, recall - 0.51613, f1_score - 0.51613\n",
      "\t  accuracy - 0.5082\n",
      "Elapsed time: 7.497\n",
      "----------------------------------------------------------------------\n",
      "Epoch 18: train loss - 1.03866, validation loss - 1.12478\n",
      "\t Validation: precision - 0.53226, recall - 0.53226, f1_score - 0.53226\n",
      "\t  accuracy - 0.51667\n",
      "Elapsed time: 7.601\n",
      "----------------------------------------------------------------------\n",
      "Epoch 19: train loss - 1.05773, validation loss - 1.11926\n",
      "\t Validation: precision - 0.53226, recall - 0.53226, f1_score - 0.53226\n",
      "\t  accuracy - 0.51667\n",
      "Elapsed time: 7.868\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 117, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 97, in main\n",
      "    model = model_implementation.code2vec_model(**kwargs)\n",
      "AttributeError: module 'model_implementation' has no attribute 'code2vec_model'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting paths from data set...\n",
      "Finished extracting paths from data set\n",
      "Calculating lines\n",
      "N: 835, train_n 709, test_n 63, val_n 63\n",
      "Extracting samples to raw files.\n",
      "Done extracting samples to raw files.\n",
      "Creating histograms from the training data\n",
      "Done creating histograms...sending to code2vec for preprocessing\n",
      "File: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.test.raw.txt\n",
      "Average total contexts: 410.6031746031746\n",
      "Average final (after sampling) contexts: 200.0\n",
      "Total examples: 63\n",
      "Empty examples: 0\n",
      "Max number of contexts per word: 708\n",
      "File: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.val.raw.txt\n",
      "Average total contexts: 424.55737704918033\n",
      "Average final (after sampling) contexts: 198.4262295081967\n",
      "Total examples: 61\n",
      "Empty examples: 0\n",
      "Max number of contexts per word: 756\n",
      "File: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.train.raw.txt\n",
      "Average total contexts: 421.7252124645892\n",
      "Average final (after sampling) contexts: 199.43626062322946\n",
      "Total examples: 706\n",
      "Empty examples: 3\n",
      "Max number of contexts per word: 3794\n",
      "{'5.0': 30, '10.0': 277, '2.5': 73, '7.5': 329}\n",
      "Dictionaries saved to: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.dict.c2v\n",
      "Epoch 1: train loss - 1.9038, validation loss - 1.39159\n",
      "\t Validation: precision - 0.44262, recall - 0.44262, f1_score - 0.44262\n",
      "\t  accuracy - 0.47287\n",
      "Elapsed time: 1.319\n",
      "----------------------------------------------------------------------\n",
      "Epoch 2: train loss - 1.42776, validation loss - 1.18764\n",
      "\t Validation: precision - 0.4918, recall - 0.4918, f1_score - 0.4918\n",
      "\t  accuracy - 0.49593\n",
      "Elapsed time: 1.108\n",
      "----------------------------------------------------------------------\n",
      "Epoch 3: train loss - 1.21383, validation loss - 1.17119\n",
      "\t Validation: precision - 0.40984, recall - 0.40984, f1_score - 0.40984\n",
      "\t  accuracy - 0.45865\n",
      "Elapsed time: 1.918\n",
      "----------------------------------------------------------------------\n",
      "Epoch 4: train loss - 1.16737, validation loss - 1.12217\n",
      "\t Validation: precision - 0.5082, recall - 0.5082, f1_score - 0.5082\n",
      "\t  accuracy - 0.50413\n",
      "Elapsed time: 3.704\n",
      "----------------------------------------------------------------------\n",
      "Epoch 5: train loss - 1.15795, validation loss - 1.10174\n",
      "\t Validation: precision - 0.57377, recall - 0.57377, f1_score - 0.57377\n",
      "\t  accuracy - 0.53982\n",
      "Elapsed time: 5.963\n",
      "----------------------------------------------------------------------\n",
      "Epoch 6: train loss - 1.12294, validation loss - 1.09156\n",
      "\t Validation: precision - 0.57377, recall - 0.57377, f1_score - 0.57377\n",
      "\t  accuracy - 0.53982\n",
      "Elapsed time: 6.912\n",
      "----------------------------------------------------------------------\n",
      "Epoch 7: train loss - 1.07608, validation loss - 1.08116\n",
      "\t Validation: precision - 0.57377, recall - 0.57377, f1_score - 0.57377\n",
      "\t  accuracy - 0.53982\n",
      "Elapsed time: 7.151\n",
      "----------------------------------------------------------------------\n",
      "Epoch 8: train loss - 1.10712, validation loss - 1.05826\n",
      "\t Validation: precision - 0.57377, recall - 0.57377, f1_score - 0.57377\n",
      "\t  accuracy - 0.53982\n",
      "Elapsed time: 7.283\n",
      "----------------------------------------------------------------------\n",
      "Epoch 9: train loss - 1.05807, validation loss - 1.0468\n",
      "\t Validation: precision - 0.57377, recall - 0.57377, f1_score - 0.57377\n",
      "\t  accuracy - 0.53982\n",
      "Elapsed time: 7.372\n",
      "----------------------------------------------------------------------\n",
      "Epoch 10: train loss - 1.03839, validation loss - 1.04198\n",
      "\t Validation: precision - 0.62295, recall - 0.62295, f1_score - 0.62295\n",
      "\t  accuracy - 0.57009\n",
      "Elapsed time: 7.459\n",
      "----------------------------------------------------------------------\n",
      "Epoch 11: train loss - 1.00016, validation loss - 1.03114\n",
      "\t Validation: precision - 0.62295, recall - 0.62295, f1_score - 0.62295\n",
      "\t  accuracy - 0.57009\n",
      "Elapsed time: 7.163\n",
      "----------------------------------------------------------------------\n",
      "Epoch 12: train loss - 0.96334, validation loss - 1.04045\n",
      "\t Validation: precision - 0.59016, recall - 0.59016, f1_score - 0.59016\n",
      "\t  accuracy - 0.54955\n",
      "Elapsed time: 6.930\n",
      "----------------------------------------------------------------------\n",
      "Epoch 13: train loss - 0.9816, validation loss - 1.05611\n",
      "\t Validation: precision - 0.59016, recall - 0.59016, f1_score - 0.59016\n",
      "\t  accuracy - 0.54955\n",
      "Elapsed time: 7.046\n",
      "----------------------------------------------------------------------\n",
      "SAB KHATAM\n",
      "Extracting paths from data set...\n",
      "Finished extracting paths from data set\n",
      "Calculating lines\n",
      "N: 72\n",
      "Extracting samples to raw files.\n",
      "Done extracting samples to raw files.\n",
      "Creating histograms from the training data\n",
      "Done creating histograms...sending to code2vec for preprocessing\n",
      "File: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.data.raw.txt\n",
      "Average total contexts: 438.60869565217394\n",
      "Average final (after sampling) contexts: 200.0\n",
      "Total examples: 69\n",
      "Empty examples: 3\n",
      "Max number of contexts per word: 1190\n",
      "Dictionaries saved to: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.dict.c2v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test.py:64: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_pred = F.softmax(y_pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   File names Predicted Marks\n",
      "0         9.c           <unk>\n",
      "1       832.c            10.0\n",
      "2       820.c            10.0\n",
      "3       818.c            10.0\n",
      "4       823.c            10.0\n",
      "..        ...             ...\n",
      "64       11.c            10.0\n",
      "65      692.c            10.0\n",
      "66      682.c           <unk>\n",
      "67      203.c            10.0\n",
      "68       15.c             7.5\n",
      "\n",
      "[69 rows x 2 columns]\n",
      "Extracting paths from data set...\n",
      "Finished extracting paths from data set\n",
      "Calculating lines\n",
      "N: 187, train_n 158, test_n 14, val_n 15\n",
      "Extracting samples to raw files.\n",
      "Done extracting samples to raw files.\n",
      "Creating histograms from the training data\n",
      "Done creating histograms...sending to code2vec for preprocessing\n",
      "File: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.test.raw.txt\n",
      "Average total contexts: 1325.3846153846155\n",
      "Average final (after sampling) contexts: 200.0\n",
      "Total examples: 13\n",
      "Empty examples: 1\n",
      "Max number of contexts per word: 2970\n",
      "File: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.val.raw.txt\n",
      "Average total contexts: 1108.5333333333333\n",
      "Average final (after sampling) contexts: 176.0\n",
      "Total examples: 15\n",
      "Empty examples: 0\n",
      "Max number of contexts per word: 3906\n",
      "File: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.train.raw.txt\n",
      "Average total contexts: 1079.1645569620252\n",
      "Average final (after sampling) contexts: 191.0506329113924\n",
      "Total examples: 158\n",
      "Empty examples: 0\n",
      "Max number of contexts per word: 4830\n",
      "{'2': 36, '3': 53, '1': 69}\n",
      "Dictionaries saved to: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.dict.c2v\n",
      "Epoch 1: train loss - 1.62552, validation loss - 1.35151\n",
      "\t Validation: precision - 0.46667, recall - 0.46667, f1_score - 0.46667\n",
      "\t  accuracy - 0.48387\n",
      "Elapsed time: 0.429\n",
      "----------------------------------------------------------------------\n",
      "Epoch 2: train loss - 1.28507, validation loss - 1.29114\n",
      "\t Validation: precision - 0.4, recall - 0.4, f1_score - 0.4\n",
      "\t  accuracy - 0.45455\n",
      "Elapsed time: 0.350\n",
      "----------------------------------------------------------------------\n",
      "Epoch 3: train loss - 1.12747, validation loss - 1.33103\n",
      "\t Validation: precision - 0.4, recall - 0.4, f1_score - 0.4\n",
      "\t  accuracy - 0.45455\n",
      "Elapsed time: 0.336\n",
      "----------------------------------------------------------------------\n",
      "Epoch 4: train loss - 1.03776, validation loss - 1.40097\n",
      "\t Validation: precision - 0.33333, recall - 0.33333, f1_score - 0.33333\n",
      "\t  accuracy - 0.42857\n",
      "Elapsed time: 0.380\n",
      "----------------------------------------------------------------------\n",
      "Epoch 5: train loss - 1.01519, validation loss - 1.37351\n",
      "\t Validation: precision - 0.4, recall - 0.4, f1_score - 0.4\n",
      "\t  accuracy - 0.45455\n",
      "Elapsed time: 0.450\n",
      "----------------------------------------------------------------------\n",
      "Epoch 6: train loss - 0.95334, validation loss - 1.36762\n",
      "\t Validation: precision - 0.4, recall - 0.4, f1_score - 0.4\n",
      "\t  accuracy - 0.45455\n",
      "Elapsed time: 0.660\n",
      "----------------------------------------------------------------------\n",
      "Epoch 7: train loss - 0.91862, validation loss - 1.33458\n",
      "\t Validation: precision - 0.4, recall - 0.4, f1_score - 0.4\n",
      "\t  accuracy - 0.45455\n",
      "Elapsed time: 0.835\n",
      "----------------------------------------------------------------------\n",
      "Epoch 8: train loss - 0.85022, validation loss - 1.33758\n",
      "\t Validation: precision - 0.53333, recall - 0.53333, f1_score - 0.53333\n",
      "\t  accuracy - 0.51724\n",
      "Elapsed time: 1.034\n",
      "----------------------------------------------------------------------\n",
      "Epoch 9: train loss - 0.83168, validation loss - 1.29579\n",
      "\t Validation: precision - 0.6, recall - 0.6, f1_score - 0.6\n",
      "\t  accuracy - 0.55556\n",
      "Elapsed time: 1.216\n",
      "----------------------------------------------------------------------\n",
      "Epoch 10: train loss - 0.7609, validation loss - 1.34674\n",
      "\t Validation: precision - 0.6, recall - 0.6, f1_score - 0.6\n",
      "\t  accuracy - 0.55556\n",
      "Elapsed time: 1.546\n",
      "----------------------------------------------------------------------\n",
      "Epoch 11: train loss - 0.73585, validation loss - 1.328\n",
      "\t Validation: precision - 0.6, recall - 0.6, f1_score - 0.6\n",
      "\t  accuracy - 0.55556\n",
      "Elapsed time: 1.768\n",
      "----------------------------------------------------------------------\n",
      "SAB KHATAM\n",
      "Extracting paths from data set...\n",
      "Finished extracting paths from data set\n",
      "Calculating lines\n",
      "N: 15\n",
      "Extracting samples to raw files.\n",
      "Done extracting samples to raw files.\n",
      "Creating histograms from the training data\n",
      "Done creating histograms...sending to code2vec for preprocessing\n",
      "File: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.data.raw.txt\n",
      "Average total contexts: 1058.9333333333334\n",
      "Average final (after sampling) contexts: 188.0\n",
      "Total examples: 15\n",
      "Empty examples: 0\n",
      "Max number of contexts per word: 2162\n",
      "Dictionaries saved to: /Users/unaissiddiqui/Desktop/Fyp/Automated_Code_Grader/data/Codes_embeddings/Codes_embeddings.dict.c2v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test.py:64: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_pred = F.softmax(y_pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   File names Predicted Marks\n",
      "0   K213241.c               2\n",
      "1   K213292.c               3\n",
      "2   K213364.c               2\n",
      "3   K213274.c               2\n",
      "4   K180149.c               3\n",
      "5   K213156.c               3\n",
      "6   K201715.c               2\n",
      "7   K213306.c           <pad>\n",
      "8   K213223.c               1\n",
      "9   K213348.c               1\n",
      "10  K213335.c               2\n",
      "11  K213253.c               1\n",
      "12  K201889.c               1\n",
      "13  K201903.c               1\n",
      "14  K213155.c               3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = Tk()\n",
    "    root_f()\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
